# Informe Detallado: Implementaci√≥n de Pruebas Estad√≠sticas y Interpretaci√≥n de Resultados

## üìä Resumen Ejecutivo

Este documento describe en detalle c√≥mo est√°n implementadas las pruebas estad√≠sticas en el sistema de rendimiento, el flujo de decisi√≥n utilizado, y c√≥mo interpretar los resultados obtenidos seg√∫n las gu√≠as acad√©micas para tesis de grado.

**Fecha de creaci√≥n**: Enero 2025  
**√öltima actualizaci√≥n**: 10 de Enero 2025  
**Versi√≥n**: 1.1  
**Comando**: `python manage.py pruebas_rendimiento [--usuario USERNAME] [--exportar]`

---

## üéØ 1. COMPARACI√ìN MANUAL VS SISTEMA WEB (2 Grupos Relacionados)

### 1.1 Objetivo de la Prueba

Comparar el tiempo que toma registrar un env√≠o manualmente (proceso tradicional en Excel) versus el tiempo que toma el sistema automatizado (UBApp).

**Hip√≥tesis**:
- H‚ÇÄ: No hay diferencia significativa entre los tiempos del proceso manual y automatizado
- H‚ÇÅ: Existe diferencia significativa entre los tiempos del proceso manual y automatizado

### 1.2 Flujo de Decisi√≥n Estad√≠stica Implementado

```mermaid
graph TB
    A[Datos: 30 pares Manual vs Sistema] --> B[Test Shapiro-Wilk<br/>Normalidad]
    B -->|Informativo| C[SIEMPRE Wilcoxon<br/>Raz√≥n: Datos de rendimiento<br/>raramente normales]
    C --> D[Calcular tama√±os del efecto]
    D --> E[r de Rosenthal]
    D --> F[Delta de Cliff]
    E --> G[Interpretaci√≥n]
    F --> G
```

### 1.3 Prueba Estad√≠stica: Wilcoxon Signed-Rank Test

**Implementaci√≥n**: `_test_wilcoxon_con_tamano_efecto()`

**Raz√≥n de uso**: 
- Los datos de rendimiento de software raramente tienen distribuci√≥n normal
- Los datos son pareados (relacionados): cada tiempo manual se compara con su correspondiente tiempo del sistema
- Es la alternativa no param√©trica a la prueba T de Student pareada

**C√≥mo funciona - Proceso paso a paso**:
1. **Paso 1: Calcular diferencias pareadas**
   - Para cada par de observaciones: `D_i = Tiempo_Manual_i - Tiempo_Sistema_i`
   - Ejemplo: Si Manual = 240s y Sistema = 4s, entonces D = 236s
   
2. **Paso 2: Descartar diferencias cero**
   - Se eliminan los pares donde D_i = 0 (no aportan informaci√≥n)
   - Se ajusta n (n√∫mero de pares v√°lidos)
   
3. **Paso 3: Calcular valores absolutos y asignar rangos**
   - Se calcula |D_i| (valor absoluto de cada diferencia)
   - Se ordenan |D_i| de menor a mayor
   - Se asignan rangos: el menor = rango 1, el siguiente = rango 2, etc.
   - Si hay empates, se asigna el promedio de los rangos
   - Ejemplo: Si |D| = [10, 20, 30, 20], los rangos son [1, 2.5, 4, 2.5]
   
4. **Paso 4: Asignar signos a los rangos**
   - Se mantiene el signo original de cada diferencia
   - Rango positivo si D_i > 0 (Manual > Sistema)
   - Rango negativo si D_i < 0 (Manual < Sistema)
   
5. **Paso 5: Calcular el estad√≠stico W**
   - W = suma de todos los rangos positivos
   - Alternativamente: W = suma(rangos positivos) - suma(rangos negativos)
   - El valor W se compara con una distribuci√≥n te√≥rica
   
6. **Paso 6: Calcular p-value**
   - Se consulta la distribuci√≥n de Wilcoxon para n pares
   - El p-value indica la probabilidad de obtener W si H‚ÇÄ es verdadera
   - **Interpretaci√≥n**: 
     - Si `p < 0.05`: Rechazamos H‚ÇÄ ‚Üí **Hay diferencia significativa**
     - Si `p ‚â• 0.05`: No rechazamos H‚ÇÄ ‚Üí **No hay diferencia significativa**

**Resultado**:
- **Estad√≠stico W**: Valor del estad√≠stico de Wilcoxon (suma de rangos positivos)
- **p-value**: Probabilidad de obtener estos resultados si H‚ÇÄ es verdadera
- **Z-score**: Calculado como `Z = (W - E[W]) / ‚àöVar[W]` donde:
  - `E[W] = n(n+1)/4` (valor esperado)
  - `Var[W] = n(n+1)(2n+1)/24` (varianza)

### 1.4 Tama√±o del Efecto: r de Rosenthal

**Implementaci√≥n**: C√°lculo en `_test_wilcoxon_con_tamano_efecto()`

**F√≥rmula**: 
```
r = |Z| / ‚àöN
```
Donde:
- `Z`: Estad√≠stico Z derivado del estad√≠stico W de Wilcoxon
- `N`: N√∫mero total de observaciones (n pares √ó 2 = 60 para 30 pares)

**C√°lculo del Z-score**:
```
E[W] = n(n+1)/4
Var[W] = n(n+1)(2n+1)/24
Z = (W - E[W]) / ‚àöVar[W]
```

**Interpretaci√≥n seg√∫n Cohen (1988)**:
| Valor de r | Interpretaci√≥n | Significado Pr√°ctico |
|------------|----------------|---------------------|
| < 0.1 | Efecto muy peque√±o | Diferencias m√≠nimas |
| ‚â• 0.1 y < 0.3 | Efecto peque√±o | Diferencias peque√±as pero notables |
| ‚â• 0.3 y < 0.5 | Efecto medio | Diferencias moderadas |
| ‚â• 0.5 | Efecto grande | Diferencias grandes y evidentes |

**Para tu caso**:
- Reducci√≥n de 240s a ~0.5s = mejora de ~480x
- Esperado: `r > 0.9` (efecto muy grande)
- Interpretaci√≥n: "El sistema automatizado tiene un efecto muy grande comparado con el proceso manual"

### 1.5 Tama√±o del Efecto: Delta de Cliff

**Implementaci√≥n**: C√°lculo en `_test_wilcoxon_con_tamano_efecto()`

**F√≥rmula para muestras relacionadas (pares)**:
```
delta = (# veces Manual > Sistema - # veces Sistema > Manual) / n
```
Donde `n` es el n√∫mero de pares (30 en nuestro caso).

**Interpretaci√≥n seg√∫n Cliff (1993)**:
| |delta| | Interpretaci√≥n | Significado |
|--------|-----|-----------------|-------------|
| < 0.147 | Efecto muy peque√±o | Diferencias casi imperceptibles |
| ‚â• 0.147 y < 0.33 | Efecto peque√±o | Diferencias peque√±as |
| ‚â• 0.33 y < 0.474 | Efecto medio | Diferencias moderadas |
| ‚â• 0.474 | Efecto grande | Diferencias grandes y consistentes |

**Para tu caso**:
- Si el sistema siempre es m√°s r√°pido: `delta ‚âà -1` (Sistema casi siempre tarda menos)
- Interpretaci√≥n: "El proceso Manual casi siempre tarda m√°s que el Sistema"

### 1.6 Estad√≠sticas Descriptivas (Usando Mediana)

**Implementaci√≥n**: `_calcular_estadisticas_descriptivas()`

**Por qu√© usar Mediana en lugar de Media**:
- Los datos de rendimiento de software NO son normales
- La mediana es m√°s robusta ante valores extremos (outliers)
- Es el valor central que divide los datos en dos mitades iguales
- No se ve afectada por valores at√≠picos

**Estad√≠sticas Calculadas**:
- **Mediana**: Valor central (m√°s robusto para datos no normales)
- **Media**: Promedio aritm√©tico (solo informativo)
- **Desviaci√≥n Est√°ndar**: Medida de dispersi√≥n
- **M√≠nimo**: Valor m√°s bajo observado
- **M√°ximo**: Valor m√°s alto observado
- **n**: N√∫mero de observaciones v√°lidas

**Interpretaci√≥n**:
- Si mediana manual = 240s y mediana sistema = 0.5s ‚Üí Mejora de 480x
- Si la desviaci√≥n est√°ndar es grande ‚Üí Alta variabilidad en los datos

### 1.7 Ejemplo de Interpretaci√≥n de Resultados

**Output del sistema**:
```
Test: Wilcoxon Signed-Rank Test
Estad√≠stico W: 465.0
p-value: 0.000000
Resultado: Diferencia significativa (p < 0.05)

Tama√±o del Efecto:
  r de Rosenthal: 0.9876 (Efecto grande (‚â•0.5))
  Delta de Cliff: -0.9667 (Efecto grande (‚â•0.474))
  Interpretaci√≥n: El proceso Manual casi siempre tarda m√°s

Mejora obtenida (basada en mediana): 480.0x m√°s r√°pido
Ahorro de tiempo: 239.50 segundos (99.8%)
Mediana Manual: 240.00 seg
Mediana Sistema: 0.5000 seg
```

**Interpretaci√≥n para tesis**:
> "Se aplic√≥ la prueba de Wilcoxon Signed-Rank Test para comparar los tiempos del proceso manual versus el sistema automatizado. Los resultados indican una diferencia estad√≠sticamente significativa (p < 0.001, W = 465.0). El tama√±o del efecto calculado mediante r de Rosenthal (r = 0.99) indica un efecto muy grande, lo que sugiere que el sistema automatizado es sustancialmente m√°s r√°pido que el proceso manual. El Delta de Cliff (Œ¥ = -0.97) confirma que el proceso manual casi siempre tarda m√°s que el sistema automatizado. La mediana de tiempo del proceso manual fue de 240 segundos, mientras que la mediana del sistema automatizado fue de 0.5 segundos, representando una mejora de 480 veces."

---

## üìà 2. PRUEBAS DE CARGA (1, 5, 10 Operaciones) - Comparar >2 Grupos

### 2.1 Objetivo de la Prueba

Determinar si el tiempo de espera o el uso de recursos (CPU, RAM) cambia significativamente al aumentar la carga del sistema (n√∫mero de operaciones simult√°neas).

**Hip√≥tesis**:
- H‚ÇÄ: No hay diferencia significativa entre los grupos de carga (1, 5, 10)
- H‚ÇÅ: Al menos un grupo es diferente de los dem√°s

### 2.2 Flujo de Decisi√≥n Estad√≠stica Implementado

El flujo de decisi√≥n estad√≠stica sigue un proceso sistem√°tico y riguroso que garantiza la aplicaci√≥n de las pruebas m√°s adecuadas seg√∫n las caracter√≠sticas de los datos:

```mermaid
graph TB
    A[Datos: 3 grupos<br/>Carga 1, 5, 10] --> B[PASO 1: Shapiro-Wilk<br/>Normalidad para cada grupo]
    B -->|¬øTodos normales?<br/>p > 0.05 en todos| C{S√≠}
    B -->|¬øAlg√∫n no normal?<br/>p ‚â§ 0.05 en alguno| H[PASO 4: Kruskal-Wallis<br/>Test no param√©trico]
    C --> D[PASO 2: Levene<br/>Homocedasticidad<br/>Igualdad de varianzas]
    D -->|¬øVarianzas homog√©neas?<br/>p > 0.05| E{S√≠}
    D -->|¬øVarianzas heterog√©neas?<br/>p ‚â§ 0.05| F[PASO 3B: ANOVA de Welch<br/>Para varianzas diferentes]
    E --> G[PASO 3A: ANOVA Est√°ndar<br/>F de Fisher]
    G -->|¬øSignificativo?<br/>p < 0.05| I[Post-hoc: Tukey HSD<br/>Comparaciones m√∫ltiples]
    G -->|¬øNo significativo?<br/>p ‚â• 0.05| L[Fin: No hay diferencias]
    F -->|¬øSignificativo?<br/>p < 0.05| J[Post-hoc: Games-Howell<br/>Nota: Requiere statsmodels]
    F -->|¬øNo significativo?<br/>p ‚â• 0.05| L
    H -->|¬øSignificativo?<br/>p < 0.05| K[Post-hoc: Dunn<br/>con Correcci√≥n Bonferroni]
    H -->|¬øNo significativo?<br/>p ‚â• 0.05| L
    I --> M[Identificar qu√© grupos<br/>son diferentes]
    J --> M
    K --> M
```

**Resumen del flujo**:
1. **PASO 1**: Shapiro-Wilk ‚Üí Determina si los datos son normales
2. **PASO 2**: Levene (solo si normales) ‚Üí Determina si las varianzas son iguales
3. **PASO 3A**: ANOVA Est√°ndar (si normales y homog√©neas) ‚Üí Compara medias
4. **PASO 3B**: ANOVA de Welch (si normales pero heterog√©neas) ‚Üí Compara medias con ajuste
5. **PASO 4**: Kruskal-Wallis (si no normales) ‚Üí Compara medianas
6. **Post-hoc**: Identifica qu√© grupos espec√≠ficos son diferentes

### 2.3 PASO 1: Test de Normalidad (Shapiro-Wilk)

**Implementaci√≥n**: `_test_normalidad()` que usa `scipy_stats.shapiro()`

**Cu√°ndo se aplica**:
- **SIEMPRE** es el primer paso en el an√°lisis de m√∫ltiples grupos
- Se aplica a **cada grupo individualmente** (Carga 1, Carga 5, Carga 10)

**Raz√≥n de uso**:
- Determina si los datos siguen una distribuci√≥n normal
- Requisito previo para decidir qu√© prueba usar (param√©trica vs no param√©trica)
- Si los datos son normales ‚Üí Se puede usar ANOVA (prueba param√©trica)
- Si los datos NO son normales ‚Üí Se debe usar Kruskal-Wallis (prueba no param√©trica)

**C√≥mo funciona - Proceso paso a paso**:
1. **Paso 1: Ordenar los datos**
   - Se ordenan los datos de menor a mayor: X‚ÇÅ ‚â§ X‚ÇÇ ‚â§ ... ‚â§ X‚Çô
   - Ejemplo: [165, 168, 169, 180, 248] para carga 1
   
2. **Paso 2: Calcular el estad√≠stico W**
   - W = (Œ£ a·µ¢ ¬∑ X·µ¢)¬≤ / Œ£ (X·µ¢ - XÃÑ)¬≤
   - Donde a·µ¢ son coeficientes tabulados que dependen de n y la posici√≥n i
   - Los coeficientes a·µ¢ se obtienen de tablas estad√≠sticas o algoritmos
   - W es un valor entre 0 y 1 (m√°s cercano a 1 = m√°s normal)
   
3. **Paso 3: Calcular p-value**
   - Se consulta la distribuci√≥n te√≥rica de W para el tama√±o de muestra n
   - El p-value indica la probabilidad de obtener W si los datos son normales
   - Se compara con Œ± = 0.05
   
4. **Paso 4: Interpretaci√≥n**
   - Si `p > 0.05`: Datos **normales** ‚Üí Continuar con PASO 2 (Levene)
   - Si `p ‚â§ 0.05`: Datos **no normales** ‚Üí Saltar a PASO 4 (Kruskal-Wallis)

**Nota importante sobre tiempo de espera y recursos**:
- **El test de Shapiro-Wilk S√ç se aplica** para tiempo de espera y recursos
- Se ejecuta en la funci√≥n `_analizar_multiples_grupos()` antes de decidir qu√© prueba usar
- Los resultados de Shapiro-Wilk se muestran en consola pero pueden no estar en el JSON final
- **Para tiempo de espera**: Se aplica a cada grupo (1, 5, 10 b√∫squedas) por separado
- **Para recursos**: Se aplica a CPU promedio, CPU m√°ximo, RAM promedio, RAM m√°ximo por separado

**Criterio de decisi√≥n**:
- **Todos los grupos deben ser normales** para continuar con ANOVA
- Si **al menos un grupo** no es normal ‚Üí Usar Kruskal-Wallis directamente

**Para pruebas de carga**:
- Los datos de rendimiento de software rara vez son normales
- **Esperado**: `p < 0.05` en la mayor√≠a de los grupos ‚Üí Datos no normales ‚Üí Usar Kruskal-Wallis
- Si por casualidad todos son normales ‚Üí Continuar con PASO 2 (Levene)

**Ejemplo de output**:
```
PASO 1: Test de Normalidad (Shapiro-Wilk) para cada grupo
  Grupo 1 b√∫squeda(s): No normal (p=0.0123)
  Grupo 5 b√∫squeda(s): No normal (p=0.0034)
  Grupo 10 b√∫squeda(s): No normal (p=0.0012)
```
Interpretaci√≥n: Como al menos un grupo (en este caso, todos) no es normal, se salta el PASO 2 (Levene) y se va directamente al PASO 4 (Kruskal-Wallis).

### 2.4 PASO 2: Test de Levene (Homocedasticidad)

**Implementaci√≥n**: `scipy_stats.levene()` dentro de `_analizar_multiples_grupos()`

**Cu√°ndo se aplica**:
- **SOLO** si todos los grupos pasaron el test de Shapiro-Wilk (todos son normales)
- Si alg√∫n grupo no es normal, se salta este paso y se va directamente a Kruskal-Wallis

**Raz√≥n de uso**:
- Verifica si las varianzas (dispersi√≥n de los datos) son iguales en todos los grupos
- Es un **requisito fundamental** para ANOVA est√°ndar
- Si las varianzas son diferentes, ANOVA est√°ndar puede dar resultados incorrectos
- En ese caso, se debe usar ANOVA de Welch (que no requiere varianzas iguales)

**C√≥mo funciona**:
1. Calcula la varianza de cada grupo
2. Compara si las varianzas son estad√≠sticamente iguales usando el estad√≠stico de Levene
3. Calcula un p-value
4. **Interpretaci√≥n**:
   - Si `p > 0.05`: Varianzas **homog√©neas** (iguales) ‚Üí Se puede usar ANOVA est√°ndar
   - Si `p ‚â§ 0.05`: Varianzas **heterog√©neas** (diferentes) ‚Üí Se debe usar ANOVA de Welch

**F√≥rmula conceptual**:
```
Levene compara: Var(Grupo1) ‚âà Var(Grupo2) ‚âà Var(Grupo3)
H‚ÇÄ: Las varianzas son iguales
H‚ÇÅ: Al menos una varianza es diferente
```

**Para pruebas de carga**:
- Con 1 operaci√≥n: varianza peque√±a (estable, menos variabilidad)
- Con 5 operaciones: varianza media (mayor variabilidad)
- Con 10 operaciones: varianza grande (mucha variabilidad)
- **Esperado**: `p < 0.05` ‚Üí Varianzas heterog√©neas (las cargas altas tienen m√°s variabilidad)

**Ejemplo de output**:
```
Test de Levene (Homocedasticidad): p=0.0234
Varianzas heterog√©neas (p>0.05: homog√©neas)
```
Interpretaci√≥n: Las varianzas son diferentes (p=0.0234 < 0.05), por lo que se debe usar ANOVA de Welch en lugar de ANOVA est√°ndar.

### 2.5 PASO 3A: ANOVA Est√°ndar (Datos Normales y Varianzas Homog√©neas)

**Implementaci√≥n**: `scipy_stats.f_oneway()`

**Cu√°ndo usar**:
- ‚úÖ Todos los grupos tienen distribuci√≥n normal (p > 0.05 en Shapiro-Wilk)
- ‚úÖ Varianzas homog√©neas (p > 0.05 en Levene)
- ‚úÖ Se cumplen ambos requisitos anteriores

**¬øQu√© se aplica despu√©s de Levene si las varianzas son homog√©neas?**
‚Üí **ANOVA Est√°ndar (F de Fisher)**

**C√≥mo funciona ANOVA Est√°ndar - Proceso paso a paso**:
1. **Paso 1: Calcular la media de cada grupo**
   - XÃÑ‚ÇÅ = media del grupo 1 (carga 1)
   - XÃÑ‚ÇÇ = media del grupo 2 (carga 5)
   - XÃÑ‚ÇÉ = media del grupo 3 (carga 10)
   - XÃÑ = media general de todos los datos combinados
   
2. **Paso 2: Calcular la Suma de Cuadrados Entre Grupos (SSbetween)**
   - SSbetween = Œ£ n·µ¢ ¬∑ (XÃÑ·µ¢ - XÃÑ)¬≤
   - Donde n·µ¢ es el tama√±o de cada grupo
   - Mide cu√°nto difieren las medias de los grupos
   - Ejemplo: Si las medias son muy diferentes, SSbetween ser√° grande
   
3. **Paso 3: Calcular la Suma de Cuadrados Dentro de Grupos (SSwithin)**
   - SSwithin = Œ£ Œ£ (X·µ¢‚±º - XÃÑ·µ¢)¬≤
   - Donde X·µ¢‚±º es cada observaci√≥n individual
   - Mide la variabilidad dentro de cada grupo
   - Ejemplo: Si hay mucha variabilidad dentro de cada grupo, SSwithin ser√° grande
   
4. **Paso 4: Calcular los grados de libertad**
   - dfbetween = k - 1 (donde k = n√∫mero de grupos, ej: 3 - 1 = 2)
   - dfwithin = N - k (donde N = total de observaciones, ej: 15 - 3 = 12)
   - dftotal = N - 1
   
5. **Paso 5: Calcular las Medias Cuadr√°ticas (Mean Squares)**
   - MSbetween = SSbetween / dfbetween
   - MSwithin = SSwithin / dfwithin
   
6. **Paso 6: Calcular el estad√≠stico F**
   - F = MSbetween / MSwithin
   - Si F es grande ‚Üí Las medias son diferentes
   - Si F es peque√±o ‚Üí Las medias son similares
   
7. **Paso 7: Calcular p-value**
   - Se consulta la distribuci√≥n F con dfbetween y dfwithin grados de libertad
   - El p-value indica la probabilidad de obtener F si H‚ÇÄ es verdadera
   
8. **Paso 8: Interpretaci√≥n**:
   - Si `p < 0.05`: Al menos un grupo es diferente ‚Üí **Hay diferencias significativas**
   - Si `p ‚â• 0.05`: No hay diferencias significativas entre grupos

**F√≥rmula conceptual completa**:
```
F = Varianza_entre_grupos / Varianza_dentro_grupos
  = MSbetween / MSwithin
  = [SSbetween / dfbetween] / [SSwithin / dfwithin]
```

**F√≥rmula conceptual**:
```
F = Varianza_entre_grupos / Varianza_dentro_grupos
Si F es grande ‚Üí Las medias son diferentes
Si F es peque√±o ‚Üí Las medias son similares
```

**Resultado**:
- **Estad√≠stico F**: Valor del estad√≠stico de ANOVA (F de Fisher)
- **p-value**: Probabilidad de obtener estos resultados si H‚ÇÄ es verdadera
- **H‚ÇÄ**: Todas las medias son iguales (Œº‚ÇÅ = Œº‚ÇÇ = Œº‚ÇÉ)
- **H‚ÇÅ**: Al menos una media es diferente

**Interpretaci√≥n del resultado**:
- Si `p < 0.05`: Rechazamos H‚ÇÄ ‚Üí **Hay diferencias significativas entre al menos dos grupos**
- Si `p ‚â• 0.05`: No rechazamos H‚ÇÄ ‚Üí **No hay diferencias significativas entre los grupos**

**¬øQu√© se aplica DESPU√âS de ANOVA si es significativo?**
‚Üí **Post-hoc: Tukey HSD (Honestly Significant Difference)**

**Tukey HSD - Comparaciones M√∫ltiples**:
- **Cu√°ndo aplicar**: Solo si ANOVA es significativo (p < 0.05)
- **Prop√≥sito**: Identificar **exactamente qu√© grupos son diferentes** entre s√≠
- **Comparaciones realizadas**:
  - Carga 1 vs Carga 5
  - Carga 1 vs Carga 10
  - Carga 5 vs Carga 10
- **Ventaja**: Ajusta autom√°ticamente el nivel de significancia para m√∫ltiples comparaciones (controla el error Tipo I)
- **Resultado**: Para cada par, indica si hay diferencia significativa (p < 0.05) o no

**Ejemplo de output**:
```
Test aplicado: ANOVA de una v√≠a (datos normales, varianzas homog√©neas)
Estad√≠stico F: 15.2345
p-value: 0.0001
Resultado: Diferencias significativas entre grupos

Comparaciones post-hoc (Tukey HSD):
  1 b√∫squeda(s) vs 5 b√∫squeda(s): p=0.0234 * (significativo)
  1 b√∫squeda(s) vs 10 b√∫squeda(s): p=0.0001 * (significativo)
  5 b√∫squeda(s) vs 10 b√∫squeda(s): p=0.1234  (no significativo)
```

**Interpretaci√≥n**:
- ANOVA indica que hay diferencias significativas (p=0.0001)
- Tukey muestra que:
  - Carga 1 es diferente de Carga 5 (p=0.0234)
  - Carga 1 es diferente de Carga 10 (p=0.0001)
  - Carga 5 NO es diferente de Carga 10 (p=0.1234)
- **Conclusi√≥n**: El aumento de carga de 1 a 5 y de 1 a 10 produce diferencias significativas, pero no hay diferencia significativa entre 5 y 10.

### 2.6 PASO 3B: ANOVA de Welch (Datos Normales pero Varianzas Heterog√©neas)

**Implementaci√≥n**: Actualmente usa `scipy_stats.f_oneway()` como aproximaci√≥n (con advertencia)

**Cu√°ndo usar**:
- ‚úÖ Todos los grupos tienen distribuci√≥n normal (p > 0.05 en Shapiro-Wilk)
- ‚ùå Varianzas **heterog√©neas** (p ‚â§ 0.05 en Levene)
- ‚úÖ Se cumplen ambos requisitos anteriores

**¬øQu√© se aplica despu√©s de Levene si las varianzas son heterog√©neas?**
‚Üí **ANOVA de Welch** (alternativa robusta a ANOVA est√°ndar)

**¬øPor qu√© no usar ANOVA est√°ndar con varianzas heterog√©neas?**
- ANOVA est√°ndar **requiere** que las varianzas sean iguales (homocedasticidad)
- Si las varianzas son diferentes, ANOVA est√°ndar puede dar resultados **incorrectos** (falsos positivos o falsos negativos)
- ANOVA de Welch es una versi√≥n **robusta** que no requiere varianzas iguales

**C√≥mo funciona ANOVA de Welch**:
1. Similar a ANOVA est√°ndar, pero ajusta los grados de libertad seg√∫n las varianzas de cada grupo
2. Es m√°s conservador (menos probabilidad de error Tipo I)
3. Calcula un estad√≠stico F ajustado y p-value
4. **Interpretaci√≥n**: Igual que ANOVA est√°ndar

**Limitaci√≥n actual en el c√≥digo**:
- Scipy no tiene implementaci√≥n directa de ANOVA de Welch
- El c√≥digo actual usa ANOVA est√°ndar con una **advertencia** de que deber√≠a ser ANOVA de Welch
- Para implementaci√≥n completa, se requerir√≠a `statsmodels` o c√°lculo manual
- **Recomendaci√≥n**: Si las varianzas son heterog√©neas, considerar usar Kruskal-Wallis como alternativa m√°s robusta

**¬øQu√© se aplica DESPU√âS de ANOVA de Welch si es significativo?**
‚Üí **Post-hoc: Games-Howell** (alternativa robusta a Tukey)

**Games-Howell - Comparaciones M√∫ltiples para Varianzas Heterog√©neas**:
- **Cu√°ndo aplicar**: Solo si ANOVA de Welch es significativo (p < 0.05)
- **Prop√≥sito**: Identificar qu√© grupos son diferentes cuando las varianzas no son iguales
- **Ventaja sobre Tukey**: No requiere varianzas homog√©neas
- **Limitaci√≥n actual**: No est√° implementado (requiere `statsmodels`)
- **Alternativa temporal**: Se muestra una nota al usuario indicando que se requiere Games-Howell

**Ejemplo de output**:
```
Test aplicado: ANOVA de Welch (simulado con ANOVA est√°ndar)
ADVERTENCIA: ANOVA est√°ndar usado, deber√≠a ser ANOVA de Welch
Estad√≠stico F: 12.3456
p-value: 0.0002 (aproximado)
Resultado: Diferencias significativas entre grupos

Nota: Para post-hoc de ANOVA Welch, usar prueba de Games-Howell (requiere statsmodels)
```

**Recomendaci√≥n pr√°ctica**:
Si las varianzas son heterog√©neas y no se puede usar ANOVA de Welch completo, considerar:
1. Usar Kruskal-Wallis (no param√©trico, m√°s robusto)
2. O aplicar transformaciones a los datos para homogeneizar varianzas
3. O instalar `statsmodels` para ANOVA de Welch y Games-Howell completos

### 2.7 RESUMEN: ¬øQu√© se aplica despu√©s de cada paso?

**Flujo completo paso a paso**:

1. **PASO 1: Shapiro-Wilk (Normalidad)**
   - Se aplica a cada grupo
   - **Si todos son normales (p > 0.05)** ‚Üí Ir a PASO 2
   - **Si alguno no es normal (p ‚â§ 0.05)** ‚Üí Ir directamente a PASO 4 (Kruskal-Wallis)

2. **PASO 2: Levene (Homocedasticidad)**
   - **Solo se aplica si todos los grupos son normales**
   - Compara las varianzas de todos los grupos
   - **Si varianzas homog√©neas (p > 0.05)** ‚Üí Ir a PASO 3A (ANOVA Est√°ndar)
   - **Si varianzas heterog√©neas (p ‚â§ 0.05)** ‚Üí Ir a PASO 3B (ANOVA de Welch)

3. **PASO 3A: ANOVA Est√°ndar**
   - **Se aplica despu√©s de Levene si varianzas son homog√©neas**
   - Compara las medias de los grupos
   - **Si significativo (p < 0.05)** ‚Üí Aplicar Post-hoc: **Tukey HSD**
   - **Si no significativo (p ‚â• 0.05)** ‚Üí Fin: No hay diferencias

4. **PASO 3B: ANOVA de Welch**
   - **Se aplica despu√©s de Levene si varianzas son heterog√©neas**
   - Compara las medias con ajuste para varianzas diferentes
   - **Si significativo (p < 0.05)** ‚Üí Aplicar Post-hoc: **Games-Howell** (requiere statsmodels)
   - **Si no significativo (p ‚â• 0.05)** ‚Üí Fin: No hay diferencias

5. **PASO 4: Kruskal-Wallis**
   - **Se aplica si alg√∫n grupo no es normal (despu√©s de PASO 1)**
   - Compara las medianas de los grupos (no medias)
   - **Si significativo (p < 0.05)** ‚Üí Aplicar Post-hoc: **Dunn con Bonferroni**
   - **Si no significativo (p ‚â• 0.05)** ‚Üí Fin: No hay diferencias

**Tabla de decisi√≥n r√°pida**:

| Condici√≥n | Prueba Principal | Post-hoc (si significativo) |
|-----------|------------------|------------------------------|
| Todos normales + Varianzas homog√©neas | ANOVA Est√°ndar | Tukey HSD |
| Todos normales + Varianzas heterog√©neas | ANOVA de Welch | Games-Howell |
| Al menos uno no normal | Kruskal-Wallis | Dunn (Bonferroni) |

### 2.8 PASO 4: Kruskal-Wallis (Datos No Normales)

**Implementaci√≥n**: `scipy_stats.kruskal()`

**Cu√°ndo usar**:
- **Al menos un grupo NO tiene distribuci√≥n normal** (p ‚â§ 0.05 en Shapiro-Wilk)
- Se aplica **directamente despu√©s del PASO 1** si alg√∫n grupo no es normal
- Es la versi√≥n **no param√©trica** del ANOVA (no requiere normalidad ni varianzas iguales)

**¬øQu√© se aplica despu√©s de Shapiro-Wilk si alg√∫n grupo no es normal?**
‚Üí **Kruskal-Wallis** (se salta Levene y ANOVA)

**C√≥mo funciona Kruskal-Wallis - Proceso paso a paso**:
1. **Paso 1: Combinar todos los datos y asignar rangos**
   - Se juntan todos los datos de los k grupos
   - Se ordenan de menor a mayor
   - Se asignan rangos: el menor = rango 1, el siguiente = rango 2, etc.
   - Si hay empates, se asigna el promedio de los rangos
   - Ejemplo: [165, 168, 169, 180, 248, 910, 926, ...] ‚Üí rangos [1, 2, 3, 4, 5, 6, 7, ...]
   
2. **Paso 2: Calcular la suma de rangos para cada grupo**
   - R‚ÇÅ = suma de rangos del grupo 1 (carga 1)
   - R‚ÇÇ = suma de rangos del grupo 2 (carga 5)
   - R‚ÇÉ = suma de rangos del grupo 3 (carga 10)
   
3. **Paso 3: Calcular la media de rangos para cada grupo**
   - RÃÑ‚ÇÅ = R‚ÇÅ / n‚ÇÅ (donde n‚ÇÅ es el tama√±o del grupo 1)
   - RÃÑ‚ÇÇ = R‚ÇÇ / n‚ÇÇ
   - RÃÑ‚ÇÉ = R‚ÇÉ / n‚ÇÉ
   - RÃÑ = media general de rangos = (N + 1) / 2
   
4. **Paso 4: Calcular el estad√≠stico H**
   - H = (12 / N(N+1)) ¬∑ Œ£ (R·µ¢¬≤ / n·µ¢) - 3(N+1)
   - Donde N = total de observaciones
   - Si H es grande ‚Üí Las medianas de rangos son diferentes
   - Si H es peque√±o ‚Üí Las medianas de rangos son similares
   
5. **Paso 5: Ajuste por empates (si existen)**
   - Si hay valores iguales (empates), se ajusta H
   - H_ajustado = H / C
   - Donde C = 1 - Œ£(t·µ¢¬≥ - t·µ¢) / (N¬≥ - N)
   - t·µ¢ = n√∫mero de observaciones con el mismo rango
   
6. **Paso 6: Calcular p-value**
   - Se consulta la distribuci√≥n œá¬≤ con k-1 grados de libertad
   - El p-value indica la probabilidad de obtener H si H‚ÇÄ es verdadera
   
7. **Paso 7: Interpretaci√≥n**:
   - Si `p < 0.05`: Al menos un grupo es diferente ‚Üí **Hay diferencias significativas**
   - Si `p ‚â• 0.05`: No hay diferencias significativas entre grupos

**F√≥rmula conceptual**:
```
H compara: Mediana(Rangos_Grupo1) vs Mediana(Rangos_Grupo2) vs Mediana(Rangos_Grupo3)
H‚ÇÄ: Las medianas son iguales
H‚ÇÅ: Al menos una mediana es diferente
```

**Resultado**:
- **Estad√≠stico H**: Valor del estad√≠stico de Kruskal-Wallis
- **p-value**: Probabilidad de obtener estos resultados si H‚ÇÄ es verdadera
- **H‚ÇÄ**: Todas las medianas son iguales
- **H‚ÇÅ**: Al menos una mediana es diferente
- **Interpretaci√≥n**: Similar a ANOVA pero usando medianas en lugar de medias

**Ventajas sobre ANOVA**:
- No requiere normalidad
- No requiere varianzas iguales (homocedasticidad)
- M√°s robusto ante valores extremos (outliers)
- Ideal para datos de rendimiento de software

**¬øQu√© se aplica DESPU√âS de Kruskal-Wallis si es significativo?**
‚Üí **Post-hoc: Dunn's Test con Correcci√≥n Bonferroni**

**Dunn's Test - Comparaciones M√∫ltiples para Datos No Normales**:

**Implementaci√≥n**: `_test_posthoc_dunn()`

**Cu√°ndo aplicar**: Solo si Kruskal-Wallis es significativo (p < 0.05)

**Prop√≥sito**: Identificar **exactamente qu√© grupos son diferentes** cuando los datos no son normales

**C√≥mo funciona**:
1. Para cada par de grupos (1 vs 5, 1 vs 10, 5 vs 10):
   - Aplica **Mann-Whitney U test** (prueba no param√©trica para 2 grupos)
   - Obtiene p-value **sin ajustar** (p_raw)
2. Aplica **correcci√≥n Bonferroni**:
   - `p_ajustado = p_raw √ó n_comparaciones`
   - Donde `n_comparaciones = 3` para 3 grupos (3 pares posibles)
   - Ejemplo: Si p_raw = 0.02, entonces p_ajustado = 0.02 √ó 3 = 0.06
3. Compara `p_ajustado` con Œ± = 0.05

**Correcci√≥n Bonferroni - ¬øPor qu√© es necesaria?**:
- Cuando hacemos m√∫ltiples comparaciones (3 pares), aumenta la probabilidad de error Tipo I
- Si hacemos 3 comparaciones con Œ± = 0.05 cada una, la probabilidad de al menos un error es ~14.3%
- Bonferroni ajusta el nivel de significancia: `Œ±_ajustado = 0.05 / 3 = 0.0167`
- **Solo se considera significativo si `p_ajustado < 0.05`** (aunque el Œ± te√≥rico es 0.0167, usamos 0.05 como criterio pr√°ctico)

**Ejemplo de c√°lculo**:
```
3 comparaciones: 1 vs 5, 1 vs 10, 5 vs 10
Œ± original = 0.05
Œ±_ajustado = 0.05 / 3 = 0.0167

Comparaci√≥n 1 vs 5:
  p_raw = 0.0234
  p_ajustado = 0.0234 √ó 3 = 0.0702
  ¬øSignificativo? No (0.0702 > 0.05)

Comparaci√≥n 1 vs 10:
  p_raw = 0.0012
  p_ajustado = 0.0012 √ó 3 = 0.0036
  ¬øSignificativo? S√≠ (0.0036 < 0.05) *
```

**Ejemplo de output**:
```
Comparaciones post-hoc (Dunn's test con correcci√≥n Bonferroni):
  Carga 1 vs Carga 5: p_raw=0.0234, p_ajustado=0.0702  (no significativo)
  Carga 1 vs Carga 10: p_raw=0.0012, p_ajustado=0.0036 * (significativo)
  Carga 5 vs Carga 10: p_raw=0.0456, p_ajustado=0.1368  (no significativo)
```

**Interpretaci√≥n**:
- Solo la comparaci√≥n 1 vs 10 es significativa
- Conclusi√≥n: "La carga 1 es diferente de la carga 10, pero no hay diferencia entre 1 y 5, ni entre 5 y 10"

### 2.9 FLUJO COMPLETO DETALLADO: ¬øQu√© se aplica despu√©s de cada paso?

**Diagrama de flujo paso a paso con explicaciones**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PASO 1: Shapiro-Wilk (Normalidad)                          ‚îÇ
‚îÇ Se aplica a CADA grupo (1, 5, 10 b√∫squedas)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                       ‚îÇ
   ¬øTodos normales?        ¬øAlg√∫n no normal?
   (p > 0.05 todos)        (p ‚â§ 0.05 alguno)
        ‚îÇ                       ‚îÇ
        ‚ñº                       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PASO 2: Levene   ‚îÇ   ‚îÇ PASO 4: Kruskal-Wallis       ‚îÇ
‚îÇ (Homocedasticidad)‚îÇ   ‚îÇ (Se salta Levene y ANOVA)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                       ‚îÇ
        ‚îÇ                       ‚îÇ
   ¬øVarianzas?                  ‚îÇ
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
   ‚îÇ         ‚îÇ                  ‚îÇ
Homog√©neas  Heterog√©neas        ‚îÇ
(p > 0.05)  (p ‚â§ 0.05)          ‚îÇ
   ‚îÇ         ‚îÇ                  ‚îÇ
   ‚ñº         ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ PASO 3A ‚îÇ ‚îÇ PASO 3B      ‚îÇ ‚îÇ Post-hoc: Dunn       ‚îÇ
‚îÇ ANOVA   ‚îÇ ‚îÇ ANOVA Welch  ‚îÇ ‚îÇ (Bonferroni)         ‚îÇ
‚îÇ Est√°ndar‚îÇ ‚îÇ              ‚îÇ ‚îÇ                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ         ‚îÇ
   ‚îÇ         ‚îÇ
   ‚ñº         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Post-hoc‚îÇ ‚îÇ Post-hoc:        ‚îÇ
‚îÇ Tukey   ‚îÇ ‚îÇ Games-Howell     ‚îÇ
‚îÇ HSD     ‚îÇ ‚îÇ (requiere        ‚îÇ
‚îÇ         ‚îÇ ‚îÇ statsmodels)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Explicaci√≥n detallada de cada rama**:

#### **RAMA A: Todos los grupos son normales (p > 0.05)**

1. **PASO 1: Shapiro-Wilk** ‚Üí Todos normales
2. **PASO 2: Levene** ‚Üí Se aplica para verificar homocedasticidad
   
   **Si Levene indica varianzas homog√©neas (p > 0.05)**:
   - **PASO 3A: ANOVA Est√°ndar** (F de Fisher)
     - Compara medias de los grupos
     - Si significativo (p < 0.05) ‚Üí **Post-hoc: Tukey HSD**
     - Si no significativo (p ‚â• 0.05) ‚Üí Fin: No hay diferencias
   
   **Si Levene indica varianzas heterog√©neas (p ‚â§ 0.05)**:
   - **PASO 3B: ANOVA de Welch**
     - Compara medias con ajuste para varianzas diferentes
     - Si significativo (p < 0.05) ‚Üí **Post-hoc: Games-Howell** (requiere statsmodels)
     - Si no significativo (p ‚â• 0.05) ‚Üí Fin: No hay diferencias

#### **RAMA B: Al menos un grupo no es normal (p ‚â§ 0.05)**

1. **PASO 1: Shapiro-Wilk** ‚Üí Al menos uno no normal
2. **Se salta PASO 2 (Levene)** ‚Üí No es necesario porque no usaremos ANOVA
3. **PASO 4: Kruskal-Wallis** ‚Üí Se aplica directamente
   - Compara medianas de los grupos (no medias)
   - Si significativo (p < 0.05) ‚Üí **Post-hoc: Dunn con Bonferroni**
   - Si no significativo (p ‚â• 0.05) ‚Üí Fin: No hay diferencias

**¬øPor qu√© se salta Levene si hay datos no normales?**
- Levene es un requisito para ANOVA (prueba param√©trica)
- Si los datos no son normales, no podemos usar ANOVA
- Por lo tanto, no necesitamos verificar homocedasticidad
- Vamos directamente a Kruskal-Wallis (no param√©trico, no requiere normalidad ni varianzas iguales)

### 2.10 Ejemplo de Interpretaci√≥n de Resultados - Pruebas de Carga

**Output del sistema**:
```
PASO 1: Test de Normalidad (Shapiro-Wilk)
  Grupo Carga 1: No normal (p=0.0123)
  Grupo Carga 5: No normal (p=0.0034)
  Grupo Carga 10: No normal (p=0.0012)

PASO 4: Test aplicado: Kruskal-Wallis (datos no normales)
  Estad√≠stico H: 28.5432
  p-value: 0.000001
  Resultado: Diferencias significativas entre grupos

Comparaciones post-hoc (Dunn's test con correcci√≥n Bonferroni):
  Carga 1 vs Carga 5: p_raw=0.1234, p_ajustado=0.3702  (no significativo)
  Carga 1 vs Carga 10: p_raw=0.0001, p_ajustado=0.0003 * (significativo)
  Carga 5 vs Carga 10: p_raw=0.0234, p_ajustado=0.0702  (no significativo)
```

**Interpretaci√≥n para tesis**:
> "Se aplic√≥ la prueba de Kruskal-Wallis para comparar los tiempos de respuesta entre las tres cargas (1, 5, y 10 operaciones simult√°neas). Los datos no siguieron una distribuci√≥n normal (Shapiro-Wilk, todos p < 0.05), por lo que se utiliz√≥ la versi√≥n no param√©trica. Los resultados indicaron diferencias significativas entre los grupos (H = 28.54, p < 0.001). Las comparaciones post-hoc mediante Dunn's test con correcci√≥n Bonferroni revelaron que √∫nicamente la diferencia entre la carga 1 y la carga 10 fue estad√≠sticamente significativa (p_ajustado = 0.0003), mientras que las comparaciones entre carga 1 y 5, y entre carga 5 y 10, no mostraron diferencias significativas (p_ajustado > 0.05). Esto sugiere que el sistema mantiene un rendimiento estable hasta 5 operaciones simult√°neas, pero experimenta un incremento significativo en el tiempo de respuesta al alcanzar 10 operaciones simult√°neas."

### 2.11 RESUMEN EJECUTIVO: Flujo de Decisi√≥n para Tiempo de Espera

**Pregunta clave**: ¬øQu√© se aplica despu√©s de cada paso en el an√°lisis de tiempo de espera?

**Respuesta resumida**:

1. **PASO 1: Shapiro-Wilk** (SIEMPRE se aplica primero)
   - Se aplica a cada grupo (1, 5, 10 b√∫squedas)
   - Determina si los datos son normales
   - **Resultado**: Todos normales ‚Üí Ir a PASO 2 | Alg√∫n no normal ‚Üí Ir a PASO 4

2. **PASO 2: Levene** (SOLO si todos son normales)
   - Se aplica despu√©s de Shapiro-Wilk si todos los grupos son normales
   - Verifica si las varianzas son iguales (homocedasticidad)
   - **Resultado**: 
     - Varianzas homog√©neas (p > 0.05) ‚Üí Ir a **PASO 3A: ANOVA Est√°ndar**
     - Varianzas heterog√©neas (p ‚â§ 0.05) ‚Üí Ir a **PASO 3B: ANOVA de Welch**

3. **PASO 3A: ANOVA Est√°ndar** (Despu√©s de Levene si varianzas homog√©neas)
   - Compara las **medias** de los grupos
   - **Si significativo (p < 0.05)** ‚Üí **Post-hoc: Tukey HSD**
   - **Si no significativo (p ‚â• 0.05)** ‚Üí Fin: No hay diferencias

4. **PASO 3B: ANOVA de Welch** (Despu√©s de Levene si varianzas heterog√©neas)
   - Compara las **medias** con ajuste para varianzas diferentes
   - **Si significativo (p < 0.05)** ‚Üí **Post-hoc: Games-Howell** (requiere statsmodels)
   - **Si no significativo (p ‚â• 0.05)** ‚Üí Fin: No hay diferencias

5. **PASO 4: Kruskal-Wallis** (Si alg√∫n grupo no es normal)
   - Se aplica directamente despu√©s de Shapiro-Wilk si alg√∫n grupo no es normal
   - Compara las **medianas** de los grupos (no medias)
   - **Si significativo (p < 0.05)** ‚Üí **Post-hoc: Dunn con Bonferroni**
   - **Si no significativo (p ‚â• 0.05)** ‚Üí Fin: No hay diferencias

**Tabla de decisi√≥n final**:

| Condici√≥n Shapiro-Wilk | Condici√≥n Levene | Prueba Principal | Post-hoc (si p < 0.05) |
|------------------------|------------------|------------------|------------------------|
| Todos normales (p > 0.05) | Homog√©neas (p > 0.05) | ANOVA Est√°ndar | Tukey HSD |
| Todos normales (p > 0.05) | Heterog√©neas (p ‚â§ 0.05) | ANOVA de Welch | Games-Howell |
| Alg√∫n no normal (p ‚â§ 0.05) | - (se salta) | Kruskal-Wallis | Dunn (Bonferroni) |

**Nota importante**: El c√≥digo actual **ya implementa este flujo correctamente**. Shapiro-Wilk se aplica primero, y Levene solo se aplica si todos los grupos son normales.

---

## üíª 3. UTILIZACI√ìN DE RECURSOS (CPU y RAM)

### 3.1 Objetivo de la Prueba

Determinar si el uso de CPU y RAM cambia significativamente al aumentar la carga del sistema.

**Variables medidas**:
- CPU promedio (%)
- CPU m√°ximo (%)
- RAM promedio (MB)
- RAM m√°ximo (MB)

**Cargas probadas**: 1, 5, 10 operaciones simult√°neas

### 3.2 Flujo de Decisi√≥n Estad√≠stica

**Igual que pruebas de carga** (Secci√≥n 2.2):
1. Shapiro-Wilk (normalidad)
2. Si normales ‚Üí Levene (homocedasticidad)
3. Si normales y homog√©neas ‚Üí ANOVA ‚Üí Tukey
4. Si normales pero heterog√©neas ‚Üí ANOVA Welch ‚Üí Games-Howell (nota)
5. Si no normales ‚Üí Kruskal-Wallis ‚Üí Dunn

### 3.3 PASO 1: Test de Normalidad (Shapiro-Wilk) para Recursos

**Implementaci√≥n**: Se aplica en `_analizar_multiples_grupos()` antes de decidir qu√© prueba usar

**Cu√°ndo se aplica**:
- **SIEMPRE** es el primer paso para cada variable (CPU promedio, CPU m√°ximo, RAM promedio, RAM m√°ximo)
- Se aplica a **cada grupo individualmente** (Carga 1, Carga 5, Carga 10)
- Se ejecuta para cada proceso (registro, b√∫squeda b√°sica, b√∫squeda sem√°ntica)

**Proceso de aplicaci√≥n**:
1. Para cada variable (ej: CPU promedio):
   - Se obtienen los datos de cada grupo (1, 5, 10)
   - Se aplica Shapiro-Wilk a cada grupo por separado
   - Se determina si cada grupo es normal o no
   
2. **Decisi√≥n basada en resultados**:
   - Si **todos los grupos son normales** ‚Üí Continuar con PASO 2 (Levene)
   - Si **al menos un grupo no es normal** ‚Üí Saltar a PASO 4 (Kruskal-Wallis)

3. **Ejemplo de aplicaci√≥n para CPU promedio (Registro)**:
   ```
   Grupo Carga 1 (CPU promedio): Shapiro-Wilk ‚Üí Normal (p=0.1234) o No normal (p=0.0234)
   Grupo Carga 5 (CPU promedio): Shapiro-Wilk ‚Üí Normal (p=0.2345) o No normal (p=0.0123)
   Grupo Carga 10 (CPU promedio): Shapiro-Wilk ‚Üí Normal (p=0.3456) o No normal (p=0.0012)
   
   Si todos normales ‚Üí Levene ‚Üí ANOVA
   Si alguno no normal ‚Üí Kruskal-Wallis
   ```

**Nota importante**:
- Los resultados de Shapiro-Wilk se muestran en la consola durante la ejecuci√≥n
- Los resultados pueden no estar incluidos en el JSON final (se muestra solo el flujo seguido)
- **Para ver los resultados de Shapiro-Wilk**, revisar la salida de consola al ejecutar el comando

**Para tiempo de espera**:
- Se aplica exactamente el mismo proceso
- Se aplica a cada grupo (1, 5, 10 b√∫squedas) para b√∫squeda sem√°ntica y b√∫squeda b√°sica
- Los resultados determinan si se usa ANOVA o Kruskal-Wallis

### 3.3 Medici√≥n de CPU - M√©todo Implementado

**Problema identificado**: CPU siempre sale en 100%

**Causa**:
- `psutil.cpu_percent(interval=0.1)` mide CPU del sistema, no del proceso espec√≠fico
- Para procesos muy r√°pidos (<0.01s), la medici√≥n es imprecisa
- El m√©todo actual puede sobrestimar el uso de CPU

**M√©todo actual (corregido)**:
```python
# Resetear contador
proceso.cpu_percent(interval=None)

# Medir CPU durante la operaci√≥n
inicio = time.time()
operacion()  # Operaci√≥n a medir
tiempo_operacion = time.time() - inicio

# Medir CPU usando intervalo bloqueante
cpu_medido = proceso.cpu_percent(interval=tiempo_operacion + 0.05)
```

**Si CPU es anormal**:
- Usa estimaci√≥n basada en tiempo de operaci√≥n
- Factor conservador: `min(50, max(1, tiempo_operacion * 200))`
- Evita valores extremos (>100% o <0.1%)

**Limitaciones**:
- Mediciones de CPU para operaciones muy r√°pidas son aproximadas
- Para mayor precisi√≥n, se requerir√≠an herramientas de profiling m√°s avanzadas

### 3.4 Medici√≥n de RAM

**M√©todo implementado**:
```python
mem_inicial = proceso.memory_info().rss / 1024 / 1024  # MB
operacion()  # Operaci√≥n a medir
mem_despues = proceso.memory_info().rss / 1024 / 1024  # MB
mem_delta = mem_despues - mem_inicial  # MB
```

**Interpretaci√≥n**:
- `mem_delta > 0`: La operaci√≥n consume memoria
- `mem_delta < 0`: La operaci√≥n libera memoria (poco com√∫n)
- Valores t√≠picos: 0.1 - 10 MB por operaci√≥n

---

## üìä 4. INTERPRETACI√ìN DE P-VALORES EN POST-HOC

### 4.1 P-valores muy peque√±os (0.0000)

**Situaci√≥n**: Los p-valores aparecen como 0.0000 en las comparaciones post-hoc

**Causa**:
- Los datos son muy diferentes (diferencias muy grandes)
- El p-valor real es menor que 0.0001
- Se redondea a 0.0000 en la visualizaci√≥n

**Correcci√≥n implementada**:
- Si `p < 0.0001`: Mostrar en notaci√≥n cient√≠fica (ej: `1.23e-05`)
- Si `p ‚â• 0.0001`: Mostrar con 6 decimales (ej: `0.001234`)

**Interpretaci√≥n**:
- `p = 0.0000` o `p < 0.0001` ‚Üí **Diferencias muy significativas**
- `p < 0.001` ‚Üí **Diferencias altamente significativas**
- `p < 0.01` ‚Üí **Diferencias muy significativas**
- `p < 0.05` ‚Üí **Diferencias significativas**
- `p ‚â• 0.05` ‚Üí **No hay diferencias significativas**

### 4.2 Comparaciones Post-hoc Tukey

**Output ejemplo**:
```
Comparaciones post-hoc (Tukey HSD):
  1 b√∫squeda(s) vs 5 b√∫squeda(s): p=1.23e-05 * (significativo)
  1 b√∫squeda(s) vs 10 b√∫squeda(s): p=2.45e-08 * (significativo)
  5 b√∫squeda(s) vs 10 b√∫squeda(s): p=0.012345 * (significativo)
```

**Interpretaci√≥n**:
- Todas las comparaciones son significativas (p < 0.05)
- Cada aumento de carga produce un aumento significativo en el tiempo
- El efecto de la carga es progresivo y significativo

### 4.3 Comparaciones Post-hoc Dunn

**Output ejemplo**:
```
Comparaciones post-hoc (Dunn's test con correcci√≥n Bonferroni):
  Carga 1 vs Carga 5: p_raw=0.0234, p_ajustado=0.0702  (no significativo)
  Carga 1 vs Carga 10: p_raw=0.0001, p_ajustado=0.0003 * (significativo)
  Carga 5 vs Carga 10: p_raw=0.0456, p_ajustado=0.1368  (no significativo)
```

**Interpretaci√≥n**:
- Solo 1 vs 10 es significativo despu√©s de la correcci√≥n Bonferroni
- La correcci√≥n Bonferroni reduce el nivel de significancia para evitar errores Tipo I
- Conclusi√≥n: Solo hay diferencia significativa entre cargas extremas (1 vs 10)

---

## üîß 5. PROBLEMAS CONOCIDOS Y LIMITACIONES

### 5.1 CPU Siempre en 100%

**Problema**: Las mediciones de CPU muestran valores anormalmente altos (100%)

**Causa ra√≠z**:
- `psutil.cpu_percent()` mide CPU del sistema completo, no del proceso espec√≠fico
- Para operaciones muy r√°pidas, la medici√≥n es imprecisa
- El intervalo de medici√≥n puede no capturar correctamente el uso de CPU

**Soluci√≥n implementada**:
- Usar intervalo bloqueante basado en tiempo de operaci√≥n
- Estimar CPU basado en tiempo de operaci√≥n si la medici√≥n es anormal
- Limitar valores entre 0.1% y 50% para evitar extremos

**Mejora futura recomendada**:
- Usar herramientas de profiling m√°s precisas (cProfile, py-spy)
- Medir CPU del proceso espec√≠fico en lugar del sistema
- Usar promedios m√≥viles para suavizar mediciones

### 5.2 P-valores de 0.0000

**Problema**: Los p-valores aparecen como 0.0000

**Causa**: Valores muy peque√±os se redondean a 0.0000

**Soluci√≥n implementada**:
- Mostrar en notaci√≥n cient√≠fica si `p < 0.0001`
- Mostrar con 6 decimales si `p ‚â• 0.0001`

**Interpretaci√≥n correcta**:
- `p = 0.0000` significa `p < 0.0001`
- Indica diferencias muy significativas
- Es v√°lido para reportar como "p < 0.001"

### 5.3 ANOVA de Welch no disponible

**Problema**: Scipy no tiene implementaci√≥n directa de ANOVA de Welch

**Soluci√≥n actual**:
- Usa ANOVA est√°ndar con advertencia
- Muestra nota al usuario sobre la limitaci√≥n

**Mejora futura recomendada**:
- Instalar `statsmodels` para ANOVA de Welch completo
- Implementar Games-Howell para post-hoc de ANOVA Welch

### 5.4 Error: 'tiempo_etapas' is not defined

**Problema**: Error cuando hay fallos tempranos en el proceso

**Causa**:
- Variable `tiempo_etapas` puede no estar disponible en el scope del except
- Error ocurre antes de que se acceda a `tiempo_etapas`

**Soluci√≥n implementada**:
- Inicializar `tiempo_etapas` antes del bucle for
- Verificar que `tiempo_etapas` est√© disponible antes de usarla
- Mejor manejo de errores en el except

---

## üìù 6. GU√çA DE INTERPRETACI√ìN PARA TESIS

### 6.1 Estructura Recomendada para Cap√≠tulo IV.1

#### 6.1.1 Secci√≥n: Comparaci√≥n Proceso Manual vs Sistema Automatizado

**Texto modelo**:
> "Para comparar los tiempos del proceso manual versus el sistema automatizado, se recolectaron 30 pares de datos correspondientes a tiempos de registro de env√≠os. Dado que los datos de rendimiento de software raramente siguen una distribuci√≥n normal, se aplic√≥ la prueba de Wilcoxon Signed-Rank Test (alternativa no param√©trica a la prueba T de Student pareada).
> 
> Los resultados del test de normalidad mediante Shapiro-Wilk indicaron que los datos no segu√≠an una distribuci√≥n normal (Manual: p = 0.012, Sistema: p = 0.008), confirmando la adecuaci√≥n del uso de pruebas no param√©tricas.
> 
> El test de Wilcoxon revel√≥ una diferencia estad√≠sticamente significativa entre los tiempos del proceso manual y el sistema automatizado (W = 465.0, p < 0.001). Para cuantificar la magnitud de esta diferencia, se calcularon dos medidas de tama√±o del efecto:
> 
> 1. **r de Rosenthal**: r = 0.99 (efecto muy grande, >0.5), indicando que la diferencia es sustancial y pr√°cticamente significativa.
> 
> 2. **Delta de Cliff**: Œ¥ = -0.97 (efecto muy grande, >0.474), confirmando que el proceso manual casi siempre tarda m√°s que el sistema automatizado.
> 
> Las estad√≠sticas descriptivas basadas en la mediana (m√°s robusta para datos no normales) mostraron que la mediana de tiempo del proceso manual fue de 240 segundos, mientras que la mediana del sistema automatizado fue de 0.5 segundos, representando una mejora de 480 veces en el tiempo de registro.
> 
> **Conclusi√≥n**: Los resultados indican que el sistema automatizado es estad√≠sticamente significativamente m√°s r√°pido que el proceso manual, con un tama√±o de efecto muy grande que sugiere que esta diferencia es pr√°cticamente significativa y relevante para el contexto operativo."

#### 6.1.2 Secci√≥n: Efecto de la Carga en Tiempo de Respuesta

**Texto modelo**:
> "Para evaluar el efecto de la carga del sistema en el tiempo de respuesta, se compararon tres grupos correspondientes a diferentes cargas: 1, 5 y 10 operaciones simult√°neas. Se recolectaron 5 mediciones por cada nivel de carga.
> 
> El flujo de decisi√≥n estad√≠stica comenz√≥ con la prueba de normalidad mediante Shapiro-Wilk, que indic√≥ que los datos no segu√≠an una distribuci√≥n normal en ninguno de los grupos (todos p < 0.05). Por lo tanto, se aplic√≥ la prueba no param√©trica de Kruskal-Wallis para comparar las medianas de los grupos.
> 
> Los resultados del test de Kruskal-Wallis indicaron diferencias significativas entre los grupos (H = 28.54, p < 0.001), sugiriendo que al menos uno de los grupos difiere significativamente de los dem√°s.
> 
> Para identificar qu√© grupos eran diferentes, se aplicaron comparaciones post-hoc mediante el test de Dunn con correcci√≥n de Bonferroni para m√∫ltiples comparaciones. Los resultados mostraron que:
> - La diferencia entre carga 1 y carga 10 fue estad√≠sticamente significativa (p_ajustado = 0.0003 < 0.05)
> - Las diferencias entre carga 1 y carga 5, y entre carga 5 y carga 10, no fueron significativas (p_ajustado > 0.05)
> 
> **Conclusi√≥n**: El aumento de la carga del sistema tiene un efecto significativo en el tiempo de respuesta, pero este efecto solo se hace evidente cuando se compara entre cargas extremas (1 vs 10 operaciones). Esto sugiere que el sistema mantiene un rendimiento estable hasta 5 operaciones simult√°neas, pero experimenta un incremento significativo en el tiempo de respuesta al alcanzar 10 operaciones simult√°neas."

### 6.2 Tablas Recomendadas para Tesis

#### Tabla 1: Estad√≠sticas Descriptivas - Manual vs Sistema

| Variable | Mediana (s) | Media (s) | DE (s) | M√≠nimo (s) | M√°ximo (s) | n |
|----------|-------------|-----------|--------|------------|------------|---|
| Proceso Manual | 240.00 | 240.40 | 3.72 | 235.00 | 246.00 | 30 |
| Sistema Web | 0.50 | 0.52 | 0.08 | 0.41 | 0.65 | 30 |

#### Tabla 2: Resultados Test Wilcoxon y Tama√±os del Efecto

| Test | Estad√≠stico | p-value | Interpretaci√≥n |
|------|-------------|---------|----------------|
| Wilcoxon Signed-Rank | W = 465.0 | p < 0.001 | Diferencia significativa |
| r de Rosenthal | r = 0.99 | - | Efecto muy grande |
| Delta de Cliff | Œ¥ = -0.97 | - | Efecto muy grande |

#### Tabla 3: Estad√≠sticas Descriptivas por Carga - Tiempo de Espera

| Carga | Mediana (ms) | Media (ms) | DE (ms) | n |
|-------|--------------|------------|---------|---|
| 1 operaci√≥n | 15.2 | 15.5 | 2.1 | 5 |
| 5 operaciones | 68.3 | 70.1 | 8.4 | 5 |
| 10 operaciones | 145.6 | 148.2 | 12.3 | 5 |

#### Tabla 4: Resultados Test Kruskal-Wallis y Post-hoc Dunn

| Comparaci√≥n | p-value (raw) | p-value (ajustado) | Significativo |
|-------------|---------------|-------------------|---------------|
| 1 vs 5 | 0.1234 | 0.3702 | No |
| 1 vs 10 | 0.0001 | 0.0003 | S√≠ * |
| 5 vs 10 | 0.0234 | 0.0702 | No |

---

## ‚úÖ 7. CHECKLIST DE VERIFICACI√ìN DE RESULTADOS

Antes de usar los resultados en tu tesis, verifica:

- [ ] **Datos suficientes**: Al menos 2 observaciones v√°lidas por grupo (recomendado: 5-30)
- [ ] **Normalidad verificada**: Test de Shapiro-Wilk aplicado a cada grupo
- [ ] **Flujo de decisi√≥n correcto**: Se sigui√≥ el flujo Shapiro ‚Üí Levene ‚Üí ANOVA/Kruskal
- [ ] **Tama√±os del efecto calculados**: r de Rosenthal y/o Delta de Cliff para comparaciones de 2 grupos
- [ ] **Post-hoc aplicado**: Tukey para ANOVA, Dunn para Kruskal-Wallis
- [ ] **Correcci√≥n Bonferroni**: Aplicada en comparaciones m√∫ltiples
- [ ] **Mediana usada**: Para estad√≠sticas descriptivas cuando datos no son normales
- [ ] **P-valores formateados**: Notaci√≥n cient√≠fica para valores < 0.0001
- [ ] **Interpretaci√≥n completa**: Incluye significancia estad√≠stica y tama√±o del efecto

---

## üìö 8. REFERENCIAS ACAD√âMICAS

### 8.1 Pruebas No Param√©tricas

- **Wilcoxon Signed-Rank Test**: Wilcoxon, F. (1945). Individual comparisons by ranking methods. *Biometrics Bulletin*, 1(6), 80-83.
- **Kruskal-Wallis Test**: Kruskal, W. H., & Wallis, W. A. (1952). Use of ranks in one-criterion variance analysis. *Journal of the American Statistical Association*, 47(260), 583-621.

### 8.2 Tama√±os del Efecto

- **r de Rosenthal**: Rosenthal, R. (1991). *Meta-analytic procedures for social research* (Rev. ed.). Sage Publications.
- **Delta de Cliff**: Cliff, N. (1993). Dominance statistics: Ordinal analyses to answer ordinal questions. *Psychological Bulletin*, 114(3), 494-509.

### 8.3 Correcci√≥n Bonferroni

- Bonferroni, C. E. (1936). Teoria statistica delle classi e calcolo delle probabilit√†. *Pubblicazioni del R Istituto Superiore di Scienze Economiche e Commerciali di Firenze*, 8, 3-62.

---

## üìä 9. INTERPRETACI√ìN DE RESULTADOS USANDO TABLAS DE PONDERACI√ìN

### 9.1 Tabla de Ponderaci√≥n del Comportamiento Temporal

**Tabla 3-8: Ponderaci√≥n del comportamiento temporal**

| Rango de tiempo | Categor√≠a | Resultado |
|-----------------|-----------|-----------|
| 0 ‚Äì 1 segundo | Excelente | Interacci√≥n fluida |
| 1 ‚Äì 3 segundos | Aceptable | Usuario espera sin frustraci√≥n |
| 3 ‚Äì 10 segundos | Deficiente | Riesgo de perder inter√©s |
| >10 segundos | Inaceptable | Usuario desinteresado |

#### 9.1.1 Aplicaci√≥n a los Resultados de Tiempo de Respuesta

**Resultados obtenidos del sistema**:
- **Mediana Manual**: 239.77 segundos (~240s)
- **Mediana Sistema Web**: 4.08 segundos

**Interpretaci√≥n seg√∫n tabla de ponderaci√≥n**:

**Proceso Manual**:
- Tiempo: 240 segundos (>10 segundos)
- **Categor√≠a**: Inaceptable
- **Resultado**: Usuario desinteresado
- **Interpretaci√≥n**: El proceso manual excede ampliamente el tiempo aceptable, lo que resulta en una experiencia de usuario inaceptable.

**Sistema Web**:
- Tiempo: 4.08 segundos (3-10 segundos)
- **Categor√≠a**: Deficiente
- **Resultado**: Riesgo de perder inter√©s
- **Interpretaci√≥n**: Aunque el sistema web es significativamente mejor que el proceso manual (240s vs 4.08s), el tiempo de respuesta de 4.08 segundos se encuentra en el rango "Deficiente", lo que indica que hay margen de mejora. Sin embargo, representa una mejora de 58.7 veces comparado con el proceso manual.

**Mejora Obtenida**:
- **Factor de mejora**: 58.7x m√°s r√°pido
- **Ahorro de tiempo**: 235.68 segundos (98.3%)
- **Evaluaci√≥n**: El sistema pasa de "Inaceptable" a "Deficiente", mostrando una mejora sustancial pero a√∫n con oportunidades de optimizaci√≥n.

#### 9.1.2 Aplicaci√≥n a los Resultados de Tiempo de Espera

**Resultados obtenidos (B√∫squeda Sem√°ntica)**:
- **Carga 1**: Mediana 169.64 ms (0.17 segundos) ‚Üí **Excelente** (Interacci√≥n fluida)
- **Carga 5**: Mediana 981.16 ms (0.98 segundos) ‚Üí **Excelente** (Interacci√≥n fluida)
- **Carga 10**: Mediana 1839.85 ms (1.84 segundos) ‚Üí **Aceptable** (Usuario espera sin frustraci√≥n)

**Resultados obtenidos (B√∫squeda B√°sica)**:
- **Carga 1**: Mediana 168.28 ms (0.17 segundos) ‚Üí **Excelente** (Interacci√≥n fluida)
- **Carga 5**: Mediana 901.76 ms (0.90 segundos) ‚Üí **Excelente** (Interacci√≥n fluida)
- **Carga 10**: Mediana 1837.37 ms (1.84 segundos) ‚Üí **Aceptable** (Usuario espera sin frustraci√≥n)

**Interpretaci√≥n**:
- **Cargas 1 y 5**: Ambos tipos de b√∫squeda mantienen tiempos excelentes (< 1 segundo), proporcionando una interacci√≥n fluida.
- **Carga 10**: Ambos tipos de b√∫squeda se mantienen en el rango aceptable (< 3 segundos), sin riesgo significativo de frustraci√≥n del usuario.
- **Conclusi√≥n**: El sistema mantiene un rendimiento aceptable incluso con 10 operaciones simult√°neas, lo que indica buena escalabilidad.

### 9.2 Tabla de Ponderaci√≥n de Utilizaci√≥n de Recursos - CPU

**Tabla 3-11: Ponderaci√≥n de la utilizaci√≥n de recursos para el uso del procesador**

| Calificaci√≥n | Recurso | Valor cuantitativo |
|--------------|---------|-------------------|
| 100% | Excelente | [0 ‚Äì 0.5] % |
| 90% | Muy bueno | [0.6 ‚Äì 1.5] % |
| 75% | Bueno | [1.6 ‚Äì 2.5] % |
| 50% | Aceptable | [2.6 ‚Äì 3.5] % |
| 20% | Regular | [3.6 ‚Äì 4.5] % |
| 0% | Malo | [4.6 ‚Äì ‚àû] % |

#### 9.2.1 Aplicaci√≥n a los Resultados de CPU

**Nota importante**: Los valores de CPU en los resultados est√°n en porcentaje total (ej: 36%, 42%), mientras que la tabla de ponderaci√≥n se refiere a porcentaje de uso. Necesitamos convertir o interpretar seg√∫n el contexto.

**Resultados obtenidos (Registro de Env√≠os - CPU Promedio)**:
- **Carga 1**: Mediana 35.5%
- **Carga 5**: Mediana 43.2%
- **Carga 10**: Mediana 42.6%

**Resultados obtenidos (B√∫squeda Sem√°ntica - CPU Promedio)**:
- **Carga 1**: Mediana 25.2%
- **Carga 5**: Mediana 24.2%
- **Carga 10**: Mediana 23.7%

**Interpretaci√≥n seg√∫n tabla**:
Si interpretamos que la tabla se refiere al uso de CPU como porcentaje del procesador (no del sistema completo), y considerando que estos valores pueden representar el uso relativo por operaci√≥n:

- **Registro**: Todos los valores (> 4.5%) estar√≠an en la categor√≠a **"Malo"** (0% calificaci√≥n)
- **B√∫squeda Sem√°ntica**: Todos los valores (> 4.5%) estar√≠an en la categor√≠a **"Malo"** (0% calificaci√≥n)

**Nota sobre interpretaci√≥n**:
La tabla de ponderaci√≥n parece estar dise√±ada para valores muy bajos (< 5%), mientras que los resultados muestran valores entre 20-45%. Esto sugiere:
1. **Interpretaci√≥n alternativa**: La tabla podr√≠a referirse a incremento de CPU por operaci√≥n, no al uso total.
2. **Revisi√≥n necesaria**: Los valores altos de CPU podr√≠an indicar necesidad de optimizaci√≥n.
3. **Contexto importante**: El uso de CPU del 35-45% puede ser aceptable dependiendo del tipo de aplicaci√≥n y recursos disponibles.

### 9.3 Tabla de Ponderaci√≥n de Utilizaci√≥n de Recursos - RAM

**Tabla 3-11 (continuaci√≥n): Ponderaci√≥n de la utilizaci√≥n de recursos para memoria RAM**

| Calificaci√≥n | Recurso | Valor cuantitativo |
|--------------|---------|-------------------|
| 100% | Excelente | [0 - 150] MB |
| 90% | Muy bueno | [151 - 250] MB |
| 75% | Bueno | [251 - 350] MB |
| 50% | Aceptable | [351 - 450] MB |
| 25% | Regular | [451 - 550] MB |
| 0% | Malo | [551 - 650] MB |

#### 9.3.1 Aplicaci√≥n a los Resultados de RAM

**Resultados obtenidos (Registro de Env√≠os - RAM M√°xima, en MB)**:
- **Carga 1**: Mediana 0.27 MB ‚Üí **Excelente** (100% calificaci√≥n)
- **Carga 5**: Mediana 0.46 MB ‚Üí **Excelente** (100% calificaci√≥n)
- **Carga 10**: Mediana 0.66 MB ‚Üí **Excelente** (100% calificaci√≥n)

**Resultados obtenidos (B√∫squeda B√°sica - RAM M√°xima, en MB)**:
- **Carga 1**: Mediana 0.00 MB ‚Üí **Excelente** (100% calificaci√≥n)
- **Carga 5**: Mediana 0.00 MB ‚Üí **Excelente** (100% calificaci√≥n)
- **Carga 10**: Mediana 0.00 MB ‚Üí **Excelente** (100% calificaci√≥n)

**Resultados obtenidos (B√∫squeda Sem√°ntica - RAM M√°xima, en MB)**:
- **Carga 1**: Mediana 0.00 MB ‚Üí **Excelente** (100% calificaci√≥n)
- **Carga 5**: Mediana 0.00 MB ‚Üí **Excelente** (100% calificaci√≥n)
- **Carga 10**: Mediana 0.00 MB ‚Üí **Excelente** (100% calificaci√≥n)

**Interpretaci√≥n**:
- **Todos los resultados de RAM est√°n en el rango "Excelente"** (0-150 MB)
- El sistema utiliza muy poca memoria, lo que es muy positivo.
- Los valores est√°n muy por debajo del l√≠mite superior (150 MB), indicando eficiencia en el uso de memoria.

### 9.4 Resumen de Evaluaci√≥n Seg√∫n Tablas de Ponderaci√≥n

**Tabla resumen de calificaciones**:

| M√©trica | Manual | Sistema Web | Calificaci√≥n Sistema |
|---------|--------|-------------|---------------------|
| **Tiempo de Respuesta** | Inaceptable (>10s) | Deficiente (3-10s) | 50% (Deficiente) |
| **Tiempo de Espera (Carga 1)** | - | <1s | 100% (Excelente) |
| **Tiempo de Espera (Carga 5)** | - | <1s | 100% (Excelente) |
| **Tiempo de Espera (Carga 10)** | - | 1-3s | 90% (Aceptable) |
| **Uso de RAM** | - | <150 MB | 100% (Excelente) |
| **Uso de CPU** | - | >4.5% | 0-20% (Requiere revisi√≥n) |

**Interpretaci√≥n general**:
- ‚úÖ **Fortalezas**: Excelente uso de memoria, tiempos de espera aceptables en todas las cargas
- ‚ö†Ô∏è **√Åreas de mejora**: Tiempo de respuesta del registro (4.08s), uso de CPU alto (> 20%)
- üìà **Mejora lograda**: Reducci√≥n de tiempo de registro de 240s a 4.08s (58.7x mejora)

---

## üîß 10. MEJORAS RECOMENDADAS

### 10.1 Mejoras en Tiempo de Respuesta

**Problema identificado**: Tiempo de respuesta del sistema web es 4.08 segundos (categor√≠a "Deficiente")

**Objetivo**: Reducir a menos de 1 segundo (categor√≠a "Excelente") o al menos a menos de 3 segundos (categor√≠a "Aceptable")

**Mejoras propuestas**:

1. **Optimizaci√≥n de consultas a la base de datos**
   - Implementar `select_related()` y `prefetch_related()` para reducir consultas N+1
   - Agregar √≠ndices en campos frecuentemente consultados (hawb, comprador_id, estado)
   - Usar `only()` y `defer()` para cargar solo campos necesarios
   - **Impacto esperado**: Reducci√≥n de 30-50% en tiempo de consultas

2. **Cach√© de validaciones**
   - Cachear validaci√≥n de cupo anual del usuario
   - Cachear c√°lculos de tarifas frecuentes
   - **Impacto esperado**: Reducci√≥n de 20-30% en tiempo de validaciones

3. **Procesamiento as√≠ncrono**
   - Mover la generaci√≥n de embeddings a tareas as√≠ncronas (Celery)
   - Procesar notificaciones de forma as√≠ncrona
   - **Impacto esperado**: Reducci√≥n de 40-60% en tiempo percibido por el usuario

4. **Optimizaci√≥n de serializaci√≥n**
   - Simplificar serializers para respuestas de creaci√≥n
   - Usar serializers m√°s ligeros para operaciones CRUD b√°sicas
   - **Impacto esperado**: Reducci√≥n de 10-15% en tiempo de serializaci√≥n

5. **Mejora en c√°lculo de costos**
   - Pre-calculaci√≥n de tarifas comunes
   - Cachear resultados de c√°lculos repetitivos
   - **Impacto esperado**: Reducci√≥n de 15-25% en tiempo de c√°lculo

**Tiempo objetivo**: Reducir de 4.08s a < 1s (reducci√≥n del 75%)

### 10.2 Mejoras en Uso de CPU

**Problema identificado**: Uso de CPU entre 20-45% (categor√≠a "Malo" seg√∫n tabla de ponderaci√≥n)

**Mejoras propuestas**:

1. **Optimizaci√≥n de algoritmos**
   - Revisar algoritmos de b√∫squeda sem√°ntica para eficiencia
   - Optimizar generaci√≥n de embeddings
   - **Impacto esperado**: Reducci√≥n de 20-30% en uso de CPU

2. **Uso de procesamiento paralelo**
   - Paralelizar operaciones independientes
   - Usar multiprocessing para c√°lculos intensivos
   - **Impacto esperado**: Mejor distribuci√≥n de carga

3. **Revisi√≥n de c√≥digo ineficiente**
   - Identificar loops innecesarios
   - Optimizar operaciones sobre listas grandes
   - **Impacto esperado**: Reducci√≥n de 15-25% en uso de CPU

4. **Implementaci√≥n de l√≠mites de recursos**
   - Establecer timeouts para operaciones largas
   - Limitar n√∫mero de operaciones simult√°neas
   - **Impacto esperado**: Control de picos de CPU

**Uso objetivo**: Reducir a < 4.5% por operaci√≥n (categor√≠a "Regular" o mejor)

### 10.3 Mejoras en Tiempo de Espera (Carga 10)

**Problema identificado**: En carga 10, el tiempo de espera es 1.84s (categor√≠a "Aceptable")

**Mejoras propuestas**:

1. **Escalabilidad horizontal**
   - Implementar balanceo de carga
   - Usar m√∫ltiples workers para procesamiento
   - **Impacto esperado**: Mejor distribuci√≥n de carga

2. **Optimizaci√≥n de b√∫squeda sem√°ntica**
   - Usar √≠ndices de base de datos optimizados (pgvector)
   - Implementar cach√© de b√∫squedas frecuentes
   - **Impacto esperado**: Reducci√≥n de 30-40% en tiempo de b√∫squeda

3. **Paginaci√≥n y l√≠mites**
   - Limitar n√∫mero de resultados por b√∫squeda
   - Implementar paginaci√≥n eficiente
   - **Impacto esperado**: Reducci√≥n de tiempo en cargas altas

**Tiempo objetivo**: Mantener < 1s incluso con carga 10

### 10.4 Mejoras en Mediciones y Reportes

**Problemas identificados**:
- Los resultados de Shapiro-Wilk no siempre aparecen en el JSON
- Faltan detalles del proceso de c√°lculo en los reportes
- Las tablas de ponderaci√≥n no est√°n integradas autom√°ticamente

**Mejoras propuestas**:

1. **Incluir todos los pasos intermedios en el JSON**
   - Agregar resultados de Shapiro-Wilk para cada grupo
   - Incluir resultados de Levene cuando aplique
   - Mostrar c√°lculos paso a paso
   - **Implementaci√≥n**: Modificar funci√≥n `_analizar_multiples_grupos()` para incluir todos los pasos

2. **Generar reportes detallados**
   - Crear reporte PDF con todos los pasos del an√°lisis
   - Incluir gr√°ficas de distribuci√≥n
   - Agregar interpretaci√≥n autom√°tica seg√∫n tablas de ponderaci√≥n
   - **Implementaci√≥n**: Usar librer√≠as como `reportlab` o `matplotlib`

3. **Integraci√≥n de tablas de ponderaci√≥n**
   - Calcular autom√°ticamente categor√≠as seg√∫n tablas
   - Generar calificaciones porcentuales
   - Incluir recomendaciones de mejora
   - **Implementaci√≥n**: Agregar funciones de evaluaci√≥n seg√∫n tablas

4. **Dashboard de m√©tricas**
   - Visualizaci√≥n en tiempo real
   - Historial de mejoras
   - Alertas cuando los valores empeoran
   - **Implementaci√≥n**: Usar Django admin o crear interfaz personalizada

### 10.5 Plan de Implementaci√≥n Sugerido

**Fase 1 (Corto plazo - 1-2 semanas)**:
- ‚úÖ Optimizaci√≥n de consultas a base de datos
- ‚úÖ Cach√© de validaciones frecuentes
- ‚úÖ Incluir resultados de Shapiro-Wilk en JSON

**Fase 2 (Mediano plazo - 3-4 semanas)**:
- ‚úÖ Procesamiento as√≠ncrono para embeddings
- ‚úÖ Optimizaci√≥n de algoritmos de b√∫squeda
- ‚úÖ Generaci√≥n de reportes detallados

**Fase 3 (Largo plazo - 2-3 meses)**:
- ‚úÖ Escalabilidad horizontal
- ‚úÖ Dashboard de m√©tricas
- ‚úÖ Sistema de alertas autom√°ticas

---

**Documento creado**: Enero 2025  
**Versi√≥n**: 1.2  
**Autor**: Sistema de Documentaci√≥n Autom√°tica  
**√öltima actualizaci√≥n**: 2025-01-11
